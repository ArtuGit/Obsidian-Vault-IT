## Core AI/ML Abbreviations

### **AGI** - Artificial General Intelligence

Hypothetical AI that matches or exceeds human cognitive abilities across all domains

### **AI** - Artificial Intelligence

Computer systems that can perform tasks typically requiring human intelligence

### **ANN** - Artificial Neural Network

Computing system inspired by biological neural networks

### **API** - Application Programming Interface

Set of protocols for building and integrating application software

### **ASR** - Automatic Speech Recognition

Technology that converts spoken language into text

### **CNN** - Convolutional Neural Network

Deep learning architecture particularly effective for image processing

### **CPU** - Central Processing Unit

Main processor of a computer system

### **CV** - Computer Vision

Field of AI that trains computers to interpret visual information

### **DL** - Deep Learning

Machine learning technique using neural networks with multiple layers

### **DNN** - Deep Neural Network

Neural network with multiple hidden layers between input and output

### **GPU** - Graphics Processing Unit

Specialized processor designed for parallel computation, essential for AI training

### **LLM** - Large Language Model

AI model trained on vast amounts of text data to understand and generate human language

### **ML** - Machine Learning

Subset of AI that enables systems to learn from data without explicit programming

### **MLOps** - Machine Learning Operations

Practices for deploying and maintaining ML models in production

### **NLP** - Natural Language Processing

AI field focused on interaction between computers and human language

### **NLU** - Natural Language Understanding

Subset of NLP focused on machine comprehension of human language

### **NN** - Neural Network

Computing system modeled after biological neural networks

### **NPU** - Neural Processing Unit

Specialized chip designed specifically for AI computations

### **OCR** - Optical Character Recognition

Technology that converts images of text into editable text

### **RNN** - Recurrent Neural Network

Neural network designed to process sequential data

### **SGD** - Stochastic Gradient Descent

Optimization algorithm used to train neural networks

### **TTS** - Text-to-Speech

Technology that converts written text into spoken words

### **TPU** - Tensor Processing Unit

Google's custom AI accelerator chips

## Language Model Specific Terms

### **BERT** - Bidirectional Encoder Representations from Transformers

Google's transformer-based language model

### **BLEU** - Bilingual Evaluation Understudy

Metric for evaluating machine translation quality

### **CLIP** - Contrastive Language-Image Pre-training

OpenAI's model that understands images and text together

### **DALL-E** - (Not an abbreviation)

OpenAI's text-to-image generation model

### **GPT** - Generative Pre-trained Transformer

OpenAI's family of language models

### **LaMDA** - Language Model for Dialogue Applications

Google's conversational AI model

### **PaLM** - Pathways Language Model

Google's large language model

### **RAG** - Retrieval-Augmented Generation

Technique combining retrieval systems with generative models

### **ROUGE** - Recall-Oriented Understudy for Gisting Evaluation

Metric for evaluating text summarization

### **T5** - Text-to-Text Transfer Transformer

Google's transformer model that treats all NLP tasks as text-to-text

### **VLLM** - Vision-Language Large Model

Models that process both visual and textual information

## Training & Fine-tuning

### **FLAN** - Finetuned Language Net

Google's instruction-tuned language model

### **LORA** - Low-Rank Adaptation

Parameter-efficient fine-tuning method

### **PEFT** - Parameter-Efficient Fine-Tuning

Methods to adapt large models with minimal parameter changes

### **RLHF** - Reinforcement Learning from Human Feedback

Training approach using human preferences to improve model behavior

### **SFT** - Supervised Fine-Tuning

Training method using labeled examples

## Technical Components

### **CUDA** - Compute Unified Device Architecture

NVIDIA's parallel computing platform for GPU programming

### **HF** - Hugging Face

Popular platform for sharing and deploying AI models

### **ONNX** - Open Neural Network Exchange

Standard for representing machine learning models

### **PyTorch** - (Not an abbreviation)

Open-source machine learning framework

### **TensorFlow** - (Not an abbreviation)

Google's open-source machine learning platform

## Evaluation & Metrics

### **BLEU** - Bilingual Evaluation Understudy

Score for machine translation quality (0-1 scale)

### **METEOR** - Metric for Evaluation of Translation with Explicit ORdering

Alternative translation evaluation metric

### **ROUGE** - Recall-Oriented Understudy for Gisting Evaluation

Metrics for text summarization evaluation

### **BERT Score** - BERT-based evaluation metric

Uses BERT embeddings to evaluate text similarity

### **GLUE** - General Language Understanding Evaluation

Benchmark for evaluating NLP models

### **SuperGLUE** - Super General Language Understanding Evaluation

More challenging successor to GLUE

## Prompting & Inference

### **COT** - Chain of Thought

Prompting technique encouraging step-by-step reasoning

### **FIM** - Fill-in-the-Middle

Text completion technique for code generation

### **ICL** - In-Context Learning

Learning from examples provided in the prompt

### **RAG** - Retrieval-Augmented Generation

Combining retrieval with generation for better responses

### **ToT** - Tree of Thoughts

Advanced prompting technique exploring multiple reasoning paths

## Model Architecture

### **FFN** - Feed-Forward Network

Component of transformer architecture

### **MHA** - Multi-Head Attention

Attention mechanism in transformer models

### **MLP** - Multi-Layer Perceptron

Type of neural network architecture

### **MSA** - Multi-Scale Attention

Attention mechanism processing multiple scales

### **RoPE** - Rotary Position Embedding

Method for encoding position information in transformers

## Data & Training

### **BPE** - Byte Pair Encoding

Tokenization method for text processing

### **SentencePiece** - (Not an abbreviation)

Tokenization library for neural text processing

### **BLEU** - Bilingual Evaluation Understudy

Metric for evaluating machine translation

### **MMLU** - Massive Multitask Language Understanding

Benchmark for evaluating broad knowledge

### **CommonCrawl** - (Not an abbreviation)

Large web crawl dataset used for training

## Specialized AI Fields

### **ASI** - Artificial Superintelligence

Hypothetical AI surpassing human intelligence in all areas

### **GAI** - Generative Artificial Intelligence

AI systems that create new content

### **MLaaS** - Machine Learning as a Service

Cloud-based ML services and platforms

### **AutoML** - Automated Machine Learning

Systems that automate ML model development

### **XAI** - Explainable AI

AI systems designed to be interpretable and transparent

## Business & Deployment

### **API** - Application Programming Interface

Interface for accessing AI services

### **SaaS** - Software as a Service

Cloud-based software delivery model

### **MLOps** - Machine Learning Operations

Practices for deploying ML models in production

### **CI/CD** - Continuous Integration/Continuous Deployment

Development practices for automated testing and deployment

### **A/B Testing** - (Not an abbreviation)

Method for comparing two versions of a system

## Emerging & Specialized Terms

### **AGI** - Artificial General Intelligence

AI with human-level performance across all cognitive tasks

### **ASI** - Artificial Superintelligence

AI exceeding human intelligence in all domains

### **FAI** - Friendly AI

AI systems aligned with human values and goals

### **AIaaS** - AI as a Service

Cloud-based AI services and platforms

### **Edge AI** - (Not an abbreviation)

AI processing performed on local devices rather than in the cloud

### **Federated Learning** - (Not an abbreviation)

Training models across distributed devices without centralizing data

---

## Quick Reference Common Patterns

- **-GPT**: Generative Pre-trained Transformer variants
- **-BERT**: Bidirectional Encoder Representations variations
- **-T5**: Text-to-Text Transfer Transformer variants
- **Multi-**: Usually refers to multiple modalities (text, image, audio)
- **Auto-**: Automated versions of processes
- **-Net**: Neural network architectures
- **-Attention**: Attention mechanism variants

---

_This vocabulary covers the most commonly used abbreviations and terms in AI/LLM discussions as of 2025. The field evolves rapidly, so new terms and abbreviations emerge regularly._